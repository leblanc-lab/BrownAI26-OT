{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# GOOGLE COLAB SETUP\n",
    "# ---------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Detected Google Colab environment.\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. Installation Check\n",
    "    # ---------------------------------------------------------\n",
    "    needs_install = False\n",
    "    \n",
    "    # Check if pot is installed\n",
    "    try:\n",
    "        import ot\n",
    "    except ImportError:\n",
    "        print(\"POT (Python Optimal Transport) not found. Installation required.\")\n",
    "        needs_install = True\n",
    "        \n",
    "    # Check if geomloss is installed\n",
    "    try:\n",
    "        import geomloss\n",
    "    except ImportError:\n",
    "        print(\"GeomLoss not found. Installation required.\")\n",
    "        needs_install = True\n",
    "\n",
    "    # Check if tqdm is installed\n",
    "    try:\n",
    "        import tqdm\n",
    "    except ImportError:\n",
    "        print(\"tqdm not found. Installation required.\")\n",
    "        needs_install = True\n",
    "\n",
    "    if needs_install:\n",
    "        print(\"Installing required packages (this may take a minute)...\")\n",
    "        !pip install -q -U pot geomloss tqdm\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INSTALLATION COMPLETE.\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "    else:\n",
    "        print(\"Environment appears correct. Skipping installation.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Download Dataset\n",
    "    # ---------------------------------------------------------\n",
    "    # MNIST is downloaded automatically by torchvision in the next cells.\n",
    "    print(\"MNIST dataset will be downloaded by torchvision.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Not running in Google Colab. Assuming local environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6269ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ot\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep: Load MNIST via torchvision and select two digits\n",
    "# Download MNIST (PIL images) and convert to numpy arrays\n",
    "mnist_train = datasets.MNIST(root='.', train=True, download=True)\n",
    "x_train = np.array([np.array(img, dtype=np.float64) for img, _ in mnist_train])\n",
    "y_train = np.array([label for _, label in mnist_train])\n",
    "\n",
    "# Select a '3' and an '8'\n",
    "idx3 = np.where(y_train == 3)[0][0]\n",
    "idx8 = np.where(y_train == 8)[0][0]\n",
    "\n",
    "img1 = x_train[idx3].astype(np.float64)\n",
    "img2 = x_train[idx8].astype(np.float64)\n",
    "\n",
    "# Normalize so pixel intensities sum to 1 (probability distributions)\n",
    "img1 /= img1.sum()\n",
    "img2 /= img2.sum()\n",
    "\n",
    "# Flatten for processing\n",
    "n_pixels = 28 * 28\n",
    "a = img1.flatten()\n",
    "b = img2.flatten()\n",
    "\n",
    "# Visualize the chosen images\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1, cmap='gray')\n",
    "plt.title(\"Source Distribution (Digit 3)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.title(\"Target Distribution (Digit 8)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d466a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry: Create Ground Cost Matrix based on pixel coordinates\n",
    "\n",
    "# Create a grid of coordinates (x, y)\n",
    "x, y = np.mgrid[0:28, 0:28]\n",
    "coords = np.vstack((x.flatten(), y.flatten())).T\n",
    "\n",
    "# Compute Euclidean distance matrix between all pairs of pixels\n",
    "# M[i, j] is the distance between pixel i and pixel j\n",
    "M = ot.dist(coords, coords, metric='euclidean')\n",
    "\n",
    "# Normalize M for numerical stability (optional but recommended)\n",
    "M /= M.max()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(M, cmap='viridis')\n",
    "plt.title(\"Ground Cost Matrix M (28x28 pixels)\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3afd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Comparison: Euclidean vs. Earth Mover's Distance\n",
    "\n",
    "# 1. Euclidean Distance (L2 Norm)\n",
    "# Does not consider geometry; treats pixels as independent features.\n",
    "euclidean_dist = np.linalg.norm(a - b)\n",
    "\n",
    "# 2. Earth Mover's Distance (Wasserstein-1)\n",
    "# Computes the minimum cost to transport mass from 'a' to 'b' given cost matrix M.\n",
    "# ot.emd2 returns the cost value.\n",
    "emd_dist = ot.emd2(a, b, M)\n",
    "\n",
    "print(f\"Euclidean Distance: {euclidean_dist:.4f}\")\n",
    "print(f\"Earth Mover's Distance: {emd_dist:.4f}\")\n",
    "\n",
    "# Comment:\n",
    "# Notice that EMD gives a meaningful distance based on the geometry of the image.\n",
    "# Even if two digits are non-overlapping, EMD will be proportional to how far the pixels need to move.\n",
    "# Euclidean distance would just be constant for non-overlapping shapes (sqrt(sum(a^2) + sum(b^2)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Transport Plan\n",
    "\n",
    "# Compute the optimal transport plan (matrix gamma)\n",
    "# gamma[i, j] is the amount of mass moved from pixel i in source to pixel j in target.\n",
    "gamma = ot.emd(a, b, M)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img1, cmap='gray')\n",
    "plt.title(\"Source (3)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.title(\"Target (8)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(gamma, cmap='hot', interpolation='nearest', origin='lower')\n",
    "plt.title(\"Transport Plan (Gamma)\")\n",
    "plt.xlabel(\"Target Pixels\")\n",
    "plt.ylabel(\"Source Pixels\")\n",
    "plt.show()\n",
    "\n",
    "print(\"The Transport Plan shows which source pixels map to which target pixels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2abd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title **Experiment 8: The \"Geodesic\" (Morphing 3 into 8)**\n",
    "# @markdown This shows *why* the flow matters. We move the ink 50% along the transport lines.\n",
    "\n",
    "# 1. Setup Coordinates\n",
    "# We need the (x,y) coordinates of every pixel to calculate the shift\n",
    "x, y = np.mgrid[0:28, 0:28]\n",
    "coords = np.vstack((x.flatten(), y.flatten())).T\n",
    "\n",
    "# 2. Define the Interpolation Function\n",
    "def make_interpolated_image(T, coords=None, side=None, t=0.5, threshold_frac=0.0):\n",
    "    \"\"\"\n",
    "    Moves mass from source to target using bilinear splatting to preserve detail.\n",
    "    - T: square transport matrix (n x n)\n",
    "    - coords: optional (n,2) pixel coordinates; if None, generated from `side`\n",
    "    - side: image side length (in pixels). If None, inferred from T.shape[0]\n",
    "    - t: interpolation fraction (0->source, 1->target)\n",
    "    - threshold_frac: fraction of T.max() below which flows are ignored (0 keeps all)\n",
    "    \"\"\"\n",
    "    n_src, n_tgt = T.shape\n",
    "    if n_src != n_tgt:\n",
    "        raise ValueError(f\\\n",
    ")\n",
    "    n = n_src\n",
    "    if side is None:\n",
    "        side = int(np.round(np.sqrt(n)))\n",
    "    if coords is None:\n",
    "        xg, yg = np.mgrid[0:side, 0:side]\n",
    "        coords = np.vstack((xg.flatten(), yg.flatten())).T\n",
    "    new_img = np.zeros((side, side), dtype=float)\n",
    "\n",
    "    # threshold (fraction of T.max()); set 0 to keep everything\n",
    "    thresh = (T.max() * threshold_frac) if threshold_frac > 0 else 0.0\n",
    "    rows, cols = np.where(T > thresh)\n",
    "\n",
    "    for r, c in zip(rows, cols):\n",
    "        mass = float(T[r, c])\n",
    "        if mass == 0:\n",
    "            continue\n",
    "        start = coords[r].astype(float)\n",
    "        end = coords[c].astype(float)\n",
    "        interp = (1 - t) * start + t * end  # continuous (x, y)\n",
    "\n",
    "        # Bilinear splat to 4 neighboring pixels to avoid hard rounding\n",
    "        x_f, y_f = interp\n",
    "        x0 = int(np.floor(x_f)); y0 = int(np.floor(y_f))\n",
    "        dx = x_f - x0; dy = y_f - y0\n",
    "\n",
    "        for ix, wx in ((x0, 1 - dx), (x0 + 1, dx)):\n",
    "            if ix < 0 or ix >= side:\n",
    "                continue\n",
    "            for iy, wy in ((y0, 1 - dy), (y0 + 1, dy)):\n",
    "                if iy < 0 or iy >= side:\n",
    "                    continue\n",
    "                new_img[ix, iy] += mass * (wx * wy)\n",
    "\n",
    "    # normalize for display\n",
    "    if new_img.max() > 0:\n",
    "        new_img /= new_img.max()\n",
    "    return new_img\n",
    "\n",
    "# 3. Generate the \"Midpoint\" Image\n",
    "side = int(np.round(np.sqrt(gamma.shape[0])))\n",
    "midpoint_img = make_interpolated_image(gamma, coords=coords, side=side, t=0.5, threshold_frac=0.0)\n",
    "# Normalize for display\n",
    "if midpoint_img.max() > 0:\n",
    "    midpoint_img /= midpoint_img.max()\n",
    "\n",
    "# 4. Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 4. Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot A: The Source (3)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img1, cmap='Greys')\n",
    "plt.title(\"Time t=0.0\\n(Source)\", fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot B: The Geodesic Midpoint (The Morph)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(midpoint_img, cmap='Greys') # Purples to show it's \"magical\"\n",
    "plt.title(\"Time t=0.5\\n(Wasserstein Interpolation)\", fontsize=14, fontweight='bold')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot C: The Target (8)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img2, cmap='Greys')\n",
    "plt.title(\"Time t=1.0\\n(Target)\", fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"Look at the middle image. It is NOT a double exposure.\")\n",
    "print(\"The top curve of the '3' has physically slid down to become the top loop of the '8'.\")\n",
    "print(\"This 'sliding' is exactly what the Transport Flow describes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e373a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Smooth animation of the transport\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Infer side and prepare frames\n",
    "side = int(np.round(np.sqrt(gamma.shape[0])))\n",
    "n_frames = 40\n",
    "ts = np.linspace(0.0, 1.0, n_frames)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "# Use consistent vmin/vmax for stable contrast\n",
    "vmin, vmax = 0.0, 1.0\n",
    "im = ax.imshow(img1 if img1.shape == (side, side) else img1.reshape(side, side), cmap='Greys', vmin=vmin, vmax=vmax)\n",
    "ax.axis('off')\n",
    "\n",
    "def update_frame(i):\n",
    "    t = ts[i]\n",
    "    frame_img = make_interpolated_image(gamma, coords=coords, side=side, t=t, threshold_frac=0.0)\n",
    "    im.set_data(frame_img)\n",
    "    ax.set_title(f\"t={t:.2f}\", fontsize=12)\n",
    "    return (im,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_frame, frames=len(ts), interval=80, blit=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# Display inline as JS animation (works in Jupyter notebooks)\n",
    "HTML(anim.to_jshtml())\n",
    "\n",
    "# Save animation as a GIF using PillowWriter (requires pillow installed)\n",
    "try:\n",
    "    writer = animation.PillowWriter(fps=12)\n",
    "    anim.save('transport_3_to_8.gif', writer=writer)\n",
    "    print('Saved animation to transport_3_to_8.gif')\n",
    "except Exception as e:\n",
    "    print('Could not save GIF:', e)\n",
    "\n",
    "# Display saved GIF inline if available\n",
    "from IPython.display import display, Image as IPImage\n",
    "try:\n",
    "    display(IPImage(filename='transport_3_to_8.gif'))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ---- Linear (cross-fade) animation: simple pixel-wise interpolation ----\n",
    "# Prepare source/target at the computed side\n",
    "src = img1 if img1.shape == (side, side) else img1.reshape(side, side)\n",
    "tgt = img2 if img2.shape == (side, side) else img2.reshape(side, side)\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(4, 4))\n",
    "im2 = ax2.imshow(src, cmap='Greys', vmin=0.0, vmax=1.0)\n",
    "ax2.axis('off')\n",
    "\n",
    "def update_fade(i):\n",
    "    t = ts[i]\n",
    "    frame = (1 - t) * src + t * tgt\n",
    "    # normalize for display to match previous visual style\n",
    "    if frame.max() > 0:\n",
    "        frame = frame / frame.max()\n",
    "    im2.set_data(frame)\n",
    "    ax2.set_title(f\"t={t:.2f}\", fontsize=12)\n",
    "    return (im2,)\n",
    "\n",
    "anim2 = animation.FuncAnimation(fig2, update_fade, frames=len(ts), interval=80, blit=True)\n",
    "plt.close(fig2)\n",
    "\n",
    "# Save linear fade GIF\n",
    "try:\n",
    "    writer = animation.PillowWriter(fps=12)\n",
    "    anim2.save('linear_3_to_8.gif', writer=writer)\n",
    "    print('Saved animation to linear_3_to_8.gif')\n",
    "except Exception as e:\n",
    "    print('Could not save linear GIF:', e)\n",
    "\n",
    "# Display saved linear GIF inline if available\n",
    "try:\n",
    "    display(IPImage(filename='linear_3_to_8.gif'))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268910d",
   "metadata": {},
   "source": [
    "## Embedding with Optimal Transport Distances\n",
    "\n",
    "We can use the Earth Mover's Distance as a metric to embed the digits into a 2D space. This allows us to visualize how \"close\" different digits are in terms of their geometry.\n",
    "\n",
    "Since computing OT distances is expensive, we will select a small subset of the dataset (e.g., 10 images per digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Selection for t-SNE\n",
    "# We'll select a subset of images to compute the pairwise OT distance matrix.\n",
    "\n",
    "n_per_digit = 50\n",
    "subset_indices = []\n",
    "subset_labels = []\n",
    "\n",
    "for digit in range(10):\n",
    "    indices = np.where(y_train == digit)[0][:n_per_digit]\n",
    "    subset_indices.extend(indices)\n",
    "    subset_labels.extend([digit] * n_per_digit)\n",
    "\n",
    "subset_images = x_train[subset_indices].astype(np.float64)\n",
    "subset_labels = np.array(subset_labels)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# COARSENING (Downsampling)\n",
    "# ---------------------------------------------------------\n",
    "# Reduce 28x28 -> 14x14 to speed up OT computation for winter school (Colab limits)\n",
    "# We'll average 2x2 blocks ...\n",
    "print(f\"Original shape: {subset_images.shape}\")\n",
    "subset_images = subset_images.reshape(-1, 14, 2, 14, 2).mean(axis=(2, 4))\n",
    "print(f\"Coarsened shape: {subset_images.shape}\")\n",
    "\n",
    "# Normalize\n",
    "subset_images = subset_images.reshape(len(subset_images), -1) # Flatten\n",
    "subset_images /= subset_images.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(f\"Selected {len(subset_images)} images ({n_per_digit} per digit).\")\n",
    "print(f\"Points per image: {subset_images.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pairwise OT Distance Matrix (Parallelized or GPU)\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, **kwargs): return x\n",
    "\n",
    "# Check for GPU\n",
    "try:\n",
    "    import torch\n",
    "    import geomloss\n",
    "    USE_GPU = torch.cuda.is_available()\n",
    "except ImportError:\n",
    "    USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    print(\"GPU detected. Using GeomLoss for accelerated Sinkhorn distances.\")\n",
    "    \n",
    "    def compute_pairwise_matrix_gpu(images, coords, batch_size=10):\n",
    "        # images: (N, n_features)\n",
    "        # coords: (n_features, 2)\n",
    "        \n",
    "        import gc\n",
    "        # Clear memory before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        device = torch.device(\"cuda\")\n",
    "        N = len(images)\n",
    "        n_features = images.shape[1]\n",
    "        \n",
    "        print(f\"Moving data to GPU... (Batch size: {batch_size}, Features: {n_features})\")\n",
    "        # Prepare data\n",
    "        # Weights must be positive and sum to 1\n",
    "        w = torch.tensor(images, dtype=torch.float32).to(device)\n",
    "        x = torch.tensor(coords, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Define Loss (Sinkhorn ~ EMD)\n",
    "        # p=1 corresponds to Euclidean distance cost (|x-y|)\n",
    "        # blur=0.05 is small enough for good approximation\n",
    "        # scaling=0.9 helps with convergence speed\n",
    "        loss_fn = geomloss.SamplesLoss(\"sinkhorn\", p=1, blur=0.05, scaling=0.9)\n",
    "        \n",
    "        D_mat = np.zeros((N, N))\n",
    "        \n",
    "        print(\"Starting GPU computation...\")\n",
    "        \n",
    "        # Loop over blocks\n",
    "        for i in tqdm(range(0, N, batch_size), desc=\"Computing Rows\"):\n",
    "            # print(f\"Processing row batch {i}/{N}...\")\n",
    "            end_i = min(i + batch_size, N)\n",
    "            len_i = end_i - i\n",
    "            \n",
    "            # Prepare batch I\n",
    "            # Shape: (len_i, 1, n_features, 2)\n",
    "            w_i = w[i:end_i].unsqueeze(1) # (len_i, 1, n_features)\n",
    "            x_i = x.unsqueeze(0).unsqueeze(0).expand(len_i, 1, -1, -1) # (len_i, 1, n_features, 2)\n",
    "            \n",
    "            # OPTIMIZATION: Only loop j starting from i (Upper Triangle)\n",
    "            for j in range(i, N, batch_size):\n",
    "                end_j = min(j + batch_size, N)\n",
    "                len_j = end_j - j\n",
    "                \n",
    "                # Prepare batch J\n",
    "                # Shape: (1, len_j, n_features, 2)\n",
    "                w_j = w[j:end_j].unsqueeze(0) # (1, len_j, n_features)\n",
    "                x_j = x.unsqueeze(0).unsqueeze(0).expand(1, len_j, -1, -1) # (1, len_j, n_features, 2)\n",
    "                \n",
    "                # Broadcast to (len_i, len_j, n_features, 2)\n",
    "                # We flatten to (len_i * len_j, n_features, 2) for geomloss\n",
    "                # NOTE: We must use .contiguous() because geomloss uses .view() internally\n",
    "                \n",
    "                w_i_flat = w_i.expand(-1, len_j, -1).contiguous().view(-1, n_features)\n",
    "                x_i_flat = x_i.expand(-1, len_j, -1, -1).contiguous().view(-1, n_features, 2)\n",
    "                \n",
    "                w_j_flat = w_j.expand(len_i, -1, -1).contiguous().view(-1, n_features)\n",
    "                x_j_flat = x_j.expand(len_i, -1, -1, -1).contiguous().view(-1, n_features, 2)\n",
    "                \n",
    "                # Compute loss\n",
    "                with torch.no_grad():\n",
    "                    # Returns (Batch,)\n",
    "                    dists = loss_fn(w_i_flat, x_i_flat, w_j_flat, x_j_flat)\n",
    "                \n",
    "                # Reshape and store\n",
    "                block_res = dists.view(len_i, len_j).cpu().numpy()\n",
    "                D_mat[i:end_i, j:end_j] = block_res\n",
    "                \n",
    "                # Symmetric fill (avoid recomputing lower triangle)\n",
    "                if i != j:\n",
    "                    D_mat[j:end_j, i:end_i] = block_res.T\n",
    "                \n",
    "                # Clean up intermediate tensors\n",
    "                del w_i_flat, x_i_flat, w_j_flat, x_j_flat, dists, block_res\n",
    "                \n",
    "            # Clear cache after each row block to prevent fragmentation\n",
    "            torch.cuda.empty_cache()\n",
    "                \n",
    "        return D_mat\n",
    "\n",
    "    # Run GPU computation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Ensure coords match the image size (important if we coarsened the data)\n",
    "    n_features = subset_images.shape[1]\n",
    "    side = int(np.sqrt(n_features))\n",
    "    \n",
    "    # Regenerate coords to match the current image resolution\n",
    "    x_grid, y_grid = np.mgrid[0:side, 0:side]\n",
    "    coords = np.vstack((x_grid.flatten(), y_grid.flatten())).T\n",
    "    \n",
    "    # If we are using coarsened images (14x14), the coordinates are 0..13.\n",
    "    # This is fine for relative distances.\n",
    "        \n",
    "    D_ot = compute_pairwise_matrix_gpu(subset_images, coords, batch_size=20)\n",
    "    print(f\"GPU Computation time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "else:\n",
    "    print(\"GPU not found or libraries missing. Using CPU parallel processing.\")\n",
    "    n_cores = multiprocessing.cpu_count()\n",
    "    print(f\"Using {n_cores} cores for computation.\")\n",
    "\n",
    "    n_samples = len(subset_images)\n",
    "    D_ot = np.zeros((n_samples, n_samples))\n",
    "\n",
    "    # Define helper function for parallel execution\n",
    "    def compute_ot_pair(i, j, img_i, img_j, M):\n",
    "        # ot.emd2 returns the transport cost\n",
    "        val = ot.emd2(img_i, img_j, M)\n",
    "        return i, j, val\n",
    "\n",
    "    print(\"Computing pairwise Wasserstein distances...\")\n",
    "    \n",
    "    # Ensure M matches the image size\n",
    "    n_features = subset_images.shape[1]\n",
    "    side = int(np.sqrt(n_features))\n",
    "    x_grid, y_grid = np.mgrid[0:side, 0:side]\n",
    "    coords = np.vstack((x_grid.flatten(), y_grid.flatten())).T\n",
    "    M = ot.dist(coords, coords, metric='euclidean')\n",
    "    M /= M.max()\n",
    "\n",
    "    # Create list of pairs (upper triangle)\n",
    "    pairs = [(i, j) for i in range(n_samples) for j in range(i + 1, n_samples)]\n",
    "    print(f\"Total pairs to compute: {len(pairs)}\")\n",
    "\n",
    "    # Run in parallel with joblib verbose output\n",
    "    results = Parallel(n_jobs=n_cores, verbose=5)(\n",
    "        delayed(compute_ot_pair)(i, j, subset_images[i], subset_images[j], M) \n",
    "        for i, j in pairs\n",
    "    )\n",
    "\n",
    "    # Fill the matrix\n",
    "    for i, j, val in results:\n",
    "        D_ot[i, j] = val\n",
    "        D_ot[j, i] = val\n",
    "\n",
    "print(\"Distance matrix computed.\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(D_ot, cmap='viridis', origin='lower')\n",
    "plt.title(\"Pairwise OT Distance Matrix\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ce77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# t-SNE Embedding with precomputed distance matrix\n",
    "tsne = TSNE(n_components=2, metric='precomputed', init='random', random_state=42, perplexity=15)\n",
    "embedding = tsne.fit_transform(D_ot)\n",
    "\n",
    "# 1. Standard Visualization (Colored Markers)\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=subset_labels, cmap='tab10', s=50, alpha=0.8)\n",
    "plt.colorbar(scatter, label='Digit Label')\n",
    "plt.title(\"t-SNE Embedding using Wasserstein Distance (Colored Markers)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 2. Visualization with Images\n",
    "def plot_embedding_images(X, images, title=None):\n",
    "    # Normalize coordinates to [0, 1] for easier scaling\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        # Reshape and normalize for display (0-1 range)\n",
    "        img = images[i].reshape(14, 14)\n",
    "        img = img / img.max() \n",
    "        \n",
    "        # Create image box\n",
    "        # zoom=0.5 controls the size of the images on the plot\n",
    "        # cmap='gray_r' inverts the colors (black digit on white background)\n",
    "        imagebox = OffsetImage(img, zoom=0.5, cmap='gray_r') \n",
    "        ab = AnnotationBbox(imagebox, (X[i, 0], X[i, 1]), frameon=False, pad=0.0)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title:\n",
    "        plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "plot_embedding_images(embedding, subset_images, \"t-SNE Embedding with MNIST Images (Wasserstein Distance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad3409",
   "metadata": {},
   "source": [
    "## Prototypes and Outliers\n",
    "\n",
    "Using the pairwise Wasserstein distances, we can identify which images are most central to their cluster (prototypes) and which are most distant (outliers).\n",
    "\n",
    "*   **Prototype:** The image with the minimum average distance to all other images of the same digit.\n",
    "*   **Outlier:** The image with the maximum average distance to all other images of the same digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Most and Least Representative Digits\n",
    "# For each digit, we find the sample with the smallest average OT distance to others of the same class (prototype)\n",
    "# and the largest average OT distance (outlier).\n",
    "\n",
    "plt.figure(figsize=(8, 20))\n",
    "\n",
    "for digit in range(10):\n",
    "    # Get indices for this digit\n",
    "    indices = np.where(subset_labels == digit)[0]\n",
    "    \n",
    "    # Extract sub-matrix of distances for this digit\n",
    "    # D_ot is the precomputed NxN distance matrix\n",
    "    sub_matrix = D_ot[np.ix_(indices, indices)]\n",
    "    \n",
    "    # Compute average distance of each sample to all others in the class\n",
    "    avg_dist = sub_matrix.mean(axis=1)\n",
    "    \n",
    "    # Find min (prototype) and max (outlier)\n",
    "    idx_proto = indices[np.argmin(avg_dist)]\n",
    "    idx_outlier = indices[np.argmax(avg_dist)]\n",
    "    \n",
    "    # Plot Prototype\n",
    "    plt.subplot(10, 2, 2 * digit + 1)\n",
    "    img_proto = subset_images[idx_proto].reshape(14, 14)\n",
    "    plt.imshow(img_proto, cmap='gray')\n",
    "    plt.title(f\"Digit {digit}: Prototype\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot Outlier\n",
    "    plt.subplot(10, 2, 2 * digit + 2)\n",
    "    img_outlier = subset_images[idx_outlier].reshape(14, 14)\n",
    "    plt.imshow(img_outlier, cmap='gray')\n",
    "    plt.title(f\"Digit {digit}: Outlier\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602c4ee",
   "metadata": {},
   "source": [
    "## Morphological Confusion Matrix\n",
    "\n",
    "The grid below shows the \"confusion candidates\" between digits.\n",
    "*   **Row $i$, Column $j$:** Displays the specific image of **Digit $i$** that has the smallest average Wasserstein distance to the cluster of **Digit $j$**.\n",
    "*   This answers questions like: *\"Which '2' looks most like a '7'?\"* or *\"Which '5' looks most like a '6'?\"*\n",
    "*   The diagonal elements $(i, i)$ correspond to the prototypes (most representative images) found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed59440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the \"Confusion Matrix\" of Morphologies\n",
    "n_classes = 10\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    indices_i = np.where(subset_labels == i)[0]\n",
    "    for j in range(n_classes):\n",
    "        indices_j = np.where(subset_labels == j)[0]\n",
    "        \n",
    "        # Extract sub-matrix of distances between class i (rows) and class j (cols)\n",
    "        # D_ot is the precomputed NxN distance matrix\n",
    "        dists = D_ot[np.ix_(indices_i, indices_j)]\n",
    "        \n",
    "        # Find sample in i that is closest to class j on average\n",
    "        # We average over the columns (target class j) to find how close each 'i' is to the 'j' cluster\n",
    "        avg_dists = dists.mean(axis=1)\n",
    "        best_idx_local = np.argmin(avg_dists)\n",
    "        best_idx_global = indices_i[best_idx_local]\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(n_classes, n_classes, i * n_classes + j + 1)\n",
    "        img = subset_images[best_idx_global].reshape(14, 14)\n",
    "        plt.imshow(img, cmap='gray_r') # Inverted gray for better visibility of thin strokes\n",
    "        \n",
    "        # Labels\n",
    "        if i == 0:\n",
    "            plt.title(f\"To {j}\")\n",
    "        if j == 0:\n",
    "            plt.ylabel(f\"From {i}\", rotation=0, ha='right', va='center')\n",
    "            \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "plt.suptitle(\"Morphological Confusion Matrix\\n(Row i, Col j: The 'i' that looks most like a 'j')\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

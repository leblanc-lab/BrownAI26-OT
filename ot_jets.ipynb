{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b34b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many studies in this notebook based on \n",
    "# https://arxiv.org/abs/1902.02346\n",
    "# The Metric Space of Collider Events\n",
    "# Patrick T. Komiske, Eric M. Metodiev, Jesse Thaler\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# GOOGLE COLAB SETUP\n",
    "# ---------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Detected Google Colab environment.\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. Smart Installation Check\n",
    "    # ---------------------------------------------------------\n",
    "    # We check the installed NumPy version via pip *before* deciding to install.\n",
    "    # This prevents the cell from hanging on re-runs after a restart.\n",
    "    \n",
    "    current_numpy_version = \"0.0.0\"\n",
    "    try:\n",
    "        # Run 'pip show numpy' to get the version on disk\n",
    "        res = subprocess.run([sys.executable, \"-m\", \"pip\", \"show\", \"numpy\"], capture_output=True, text=True)\n",
    "        m = re.search(r\"Version:\\s*(\\d+\\.\\d+\\.\\d+)\", res.stdout)\n",
    "        if m:\n",
    "            current_numpy_version = m.group(1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"Current NumPy version on disk: {current_numpy_version}\")\n",
    "    \n",
    "    # Determine if we need to install/downgrade\n",
    "    needs_install = False\n",
    "    \n",
    "    # Condition 1: NumPy must be 1.x\n",
    "    if not current_numpy_version.startswith(\"1.\"):\n",
    "        print(\"NumPy 2.x (or unknown) detected. Downgrade required.\")\n",
    "        needs_install = True\n",
    "    else:\n",
    "        # Condition 2: Check if energyflow/geomloss are installed\n",
    "        res_pkg = subprocess.run([sys.executable, \"-m\", \"pip\", \"show\", \"energyflow\"], capture_output=True, text=True)\n",
    "        if \"Name: energyflow\" not in res_pkg.stdout:\n",
    "            print(\"energyflow not found. Installation required.\")\n",
    "            needs_install = True\n",
    "\n",
    "    if needs_install:\n",
    "        print(\"Installing required packages (this may take a minute)...\")\n",
    "        # AGGRESSIVE COMPATIBILITY FIX:\n",
    "        # Force reinstall to ensure we get numpy<2.0.0 and compatible scipy/sklearn\n",
    "        # Added geomloss for GPU OT\n",
    "        !pip install -q -U --force-reinstall \"numpy<2.0.0\" \"scipy<1.13.0\" \"scikit-learn<1.5.0\" energyflow pot uproot awkward vector geomloss\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INSTALLATION COMPLETE.\")\n",
    "        print(\"CRITICAL: You MUST restart the Colab runtime now.\")\n",
    "        print(\"1. Go to menu: Runtime > Restart session\")\n",
    "        print(\"2. Run this cell again (it will skip installation next time)\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "    else:\n",
    "        print(\"Environment appears correct (NumPy 1.x installed). Skipping installation.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Download Dataset\n",
    "    # ---------------------------------------------------------\n",
    "    folder_id = '1CJe9xkIk1QmTXJ8g__zagAvn3uoxue5a'\n",
    "    output_folder = 'efjets'\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        print(f\"Downloading dataset to {output_folder}/...\")\n",
    "        !pip install -q -U --no-cache-dir gdown --pre\n",
    "        import gdown\n",
    "        gdown.download_folder(id=folder_id, output=output_folder, quiet=False)\n",
    "    else:\n",
    "        print(f\"Folder '{output_folder}' already exists. Skipping download.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Not running in Google Colab. Assuming local environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# CRITICAL: Check NumPy version before importing other libraries\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "if np.__version__ >= '2.0.0':\n",
    "    msg = (\n",
    "        f\"Detected NumPy {np.__version__}, but this notebook requires NumPy < 2.0.0.\\n\"\n",
    "        \"Please run the 'GOOGLE COLAB SETUP' cell above to install the correct versions,\\n\"\n",
    "        \"then RESTART the runtime (Runtime > Restart session) and run this cell again.\"\n",
    "    )\n",
    "    raise RuntimeError(msg)\n",
    "\n",
    "import ot\n",
    "import energyflow as ef\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eea038",
   "metadata": {},
   "source": [
    "## 1. Data Loading: EnergyFlow Datasets\n",
    "\n",
    "We will load jets from the `efjets/` directory.\n",
    "*   **Quark Jets:** From `QG_jets` files (Label 1).\n",
    "*   **Gluon Jets:** From `QG_jets` files (Label 0).\n",
    "*   **Top Jets:** From `top_qcd` files (Label 1).\n",
    "\n",
    "The data format is `(N, M, 4)` where features are `(pt, y, phi, pid)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Logic\n",
    "\n",
    "# Define classes for our analysis\n",
    "# We will map original labels to these new IDs\n",
    "# 0: Gluon\n",
    "# 1: Quark\n",
    "# 2: Top\n",
    "class_names = {\n",
    "    0: 'Gluon',\n",
    "    1: 'Quark',\n",
    "    2: 'Top'\n",
    "}\n",
    "\n",
    "def preprocess_jets(X, y, source_type, max_jets=1000, max_particles=128):\n",
    "    \"\"\"\n",
    "    Convert (N, M, 4) array to list of (M, 2) coordinates and weights.\n",
    "    source_type: 'QG' or 'Top' to handle label mapping.\n",
    "    \"\"\"\n",
    "    jets_X = []\n",
    "    jets_w = []\n",
    "    jets_pt = []\n",
    "    labels = []\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if count >= max_jets:\n",
    "            break\n",
    "            \n",
    "        # Extract features: (pt, y, phi, pid)\n",
    "        # We use y (rapidity) and phi\n",
    "        jet_data = X[i]\n",
    "        \n",
    "        # Filter zero-padded particles (pt=0)\n",
    "        mask = jet_data[:, 0] > 0\n",
    "        if np.sum(mask) < 2: continue # Skip empty/single particle jets\n",
    "        \n",
    "        pts = jet_data[mask, 0]\n",
    "        ys  = jet_data[mask, 1]\n",
    "        phis = jet_data[mask, 2]\n",
    "        \n",
    "        # Store total pT before normalization\n",
    "        total_pt = pts.sum()\n",
    "        \n",
    "        # Limit particles\n",
    "        if len(pts) > max_particles:\n",
    "            # Sort by pt descending\n",
    "            idx = np.argsort(pts)[::-1][:max_particles]\n",
    "            pts = pts[idx]\n",
    "            ys = ys[idx]\n",
    "            phis = phis[idx]\n",
    "            \n",
    "        # Centering\n",
    "        # Note: phi periodicity is handled by centering if the jet is localized\n",
    "        # For safety, we can re-wrap phi after centering, but usually not strictly necessary for small R jets\n",
    "        y_avg = np.average(ys, weights=pts)\n",
    "        \n",
    "        # Circular mean for phi\n",
    "        phi_avg = np.arctan2(np.average(np.sin(phis), weights=pts), \n",
    "                             np.average(np.cos(phis), weights=pts))\n",
    "                             \n",
    "        ys_centered = ys - y_avg\n",
    "        phis_centered = phis - phi_avg\n",
    "        \n",
    "        # Wrap phi to [-pi, pi]\n",
    "        phis_centered = (phis_centered + np.pi) % (2 * np.pi) - np.pi\n",
    "        \n",
    "        # Construct (N, 2) array\n",
    "        X_i = np.stack([ys_centered, phis_centered], axis=1)\n",
    "        \n",
    "        # Weights (normalized pT)\n",
    "        w_i = pts / pts.sum()\n",
    "        \n",
    "        # Determine Label\n",
    "        original_label = int(y[i])\n",
    "        new_label = -1\n",
    "        \n",
    "        if source_type == 'QG':\n",
    "            # Original: 0=Gluon, 1=Quark\n",
    "            # Map: 0->0 (Gluon), 1->1 (Quark)\n",
    "            new_label = original_label\n",
    "        elif source_type == 'Top':\n",
    "            # Original: 0=QCD, 1=Top\n",
    "            # We only want Top (1)\n",
    "            if original_label == 1:\n",
    "                new_label = 2 # Top\n",
    "            else:\n",
    "                continue # Skip QCD from this file\n",
    "        \n",
    "        jets_X.append(X_i)\n",
    "        jets_w.append(w_i)\n",
    "        jets_pt.append(total_pt)\n",
    "        labels.append(new_label)\n",
    "        count += 1\n",
    "        \n",
    "    return jets_X, jets_w, labels, jets_pt\n",
    "\n",
    "def load_ef_data(max_jets_per_class=250):\n",
    "    all_X = []\n",
    "    all_w = []\n",
    "    all_labels = []\n",
    "    all_pt = []\n",
    "    \n",
    "    # 1. Load QG Jets\n",
    "    qg_files = glob.glob('efjets/QG_jets_*.npz')\n",
    "    print(f\"Found {len(qg_files)} QG files.\")\n",
    "    \n",
    "    jets_needed = max_jets_per_class * 2 # Gluon + Quark\n",
    "    jets_loaded = 0\n",
    "    \n",
    "    for f in qg_files:\n",
    "        if jets_loaded >= jets_needed: break\n",
    "        print(f\"Loading {f}...\")\n",
    "        data = np.load(f)\n",
    "        # QG files use 'X' and 'y'\n",
    "        X_raw = data['X']\n",
    "        y_raw = data['y'] # 0=Gluon, 1=Quark\n",
    "        \n",
    "        # We want roughly equal mix, so let's just load and filter later or load enough\n",
    "        # Simple approach: Load chunk, process\n",
    "        X_proc, w_proc, l_proc, pt_proc = preprocess_jets(X_raw, y_raw, 'QG', max_jets=jets_needed)\n",
    "        \n",
    "        all_X.extend(X_proc)\n",
    "        all_w.extend(w_proc)\n",
    "        all_labels.extend(l_proc)\n",
    "        all_pt.extend(pt_proc)\n",
    "        jets_loaded += len(X_proc)\n",
    "\n",
    "    # 2. Load Top Jets\n",
    "    top_files = glob.glob('efjets/top_qcd_*.npz')\n",
    "    print(f\"Found {len(top_files)} Top/QCD files.\")\n",
    "    \n",
    "    jets_needed_top = max_jets_per_class\n",
    "    jets_loaded_top = 0\n",
    "    \n",
    "    for f in top_files:\n",
    "        if jets_loaded_top >= jets_needed_top: break\n",
    "        print(f\"Loading {f}...\")\n",
    "        data = np.load(f)\n",
    "        \n",
    "        # FIX: Check for keys, as top_qcd files might use 'data'/'labels'\n",
    "        if 'data' in data:\n",
    "            X_raw = data['data']\n",
    "            y_raw = data['labels']\n",
    "        else:\n",
    "            X_raw = data['X']\n",
    "            y_raw = data['y']\n",
    "        \n",
    "        X_proc, w_proc, l_proc, pt_proc = preprocess_jets(X_raw, y_raw, 'Top', max_jets=jets_needed_top*4) # Load more to find Tops\n",
    "        \n",
    "        all_X.extend(X_proc)\n",
    "        all_w.extend(w_proc)\n",
    "        all_labels.extend(l_proc)\n",
    "        all_pt.extend(pt_proc)\n",
    "        jets_loaded_top += len(l_proc)\n",
    "\n",
    "    # Subsample to balance classes exactly\n",
    "    final_X = []\n",
    "    final_w = []\n",
    "    final_labels = []\n",
    "    final_pt = []\n",
    "    \n",
    "    arr_labels = np.array(all_labels)\n",
    "    \n",
    "    for cls_id in [0, 1, 2]:\n",
    "        indices = np.where(arr_labels == cls_id)[0]\n",
    "        if len(indices) > max_jets_per_class:\n",
    "            indices = np.random.choice(indices, max_jets_per_class, replace=False)\n",
    "        \n",
    "        print(f\"Class {class_names[cls_id]}: {len(indices)} jets\")\n",
    "        \n",
    "        for idx in indices:\n",
    "            final_X.append(all_X[idx])\n",
    "            final_w.append(all_w[idx])\n",
    "            final_labels.append(all_labels[idx])\n",
    "            final_pt.append(all_pt[idx])\n",
    "            \n",
    "    return final_X, final_w, np.array(final_labels), np.array(final_pt)\n",
    "\n",
    "# Load\n",
    "jets_X, jets_w, labels, jets_pt = load_ef_data(max_jets_per_class=500)\n",
    "N = len(jets_X)\n",
    "print(f\"Total jets loaded: {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936637a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization & Utility Functions\n",
    "\n",
    "def plot_jet_scatter(ax, x0, y0, X, w, scale=0.25, max_markersize=60, cmap='viridis', alpha=0.8):\n",
    "    xs = x0 + X[:, 0] * scale\n",
    "    ys = y0 + X[:, 1] * scale\n",
    "    s = (w / (w.max() + 1e-12)) * max_markersize\n",
    "    ax.scatter(xs, ys, s=s, c=w, cmap=cmap, alpha=alpha, edgecolors='none')\n",
    "\n",
    "print(\"Visualization utilities defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21498200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# VISUALIZATION: OT Plan & Animation\n",
    "# ---------------------------------------------------------\n",
    "# We select two random jets and visualize the transport plan.\n",
    "# Uses EnergyFlow (ef.emd.emd) for IRC-safe EMD calculation.\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# CONFIGURATION: Select classes to compare\n",
    "# 0: Gluon, 1: Quark, 2: Top\n",
    "source_class_id = 1 # Quark\n",
    "target_class_id = 2 # Top\n",
    "\n",
    "source_name = class_names[source_class_id]\n",
    "target_name = class_names[target_class_id]\n",
    "\n",
    "print(f\"Visualizing transport from {source_name} to {target_name}...\")\n",
    "\n",
    "# Select first available jet of each class\n",
    "idx_source = np.where(labels == source_class_id)[0][0]\n",
    "idx_target = np.where(labels == target_class_id)[0][0]\n",
    "\n",
    "X_source, w_source = jets_X[idx_source], jets_w[idx_source]\n",
    "X_target, w_target = jets_X[idx_target], jets_w[idx_target]\n",
    "\n",
    "# Prepare events for EnergyFlow: (pt, y, phi)\n",
    "# jets_X is (y, phi), jets_w is pt (normalized)\n",
    "ev_source = np.column_stack((w_source, X_source))\n",
    "ev_target = np.column_stack((w_target, X_target))\n",
    "\n",
    "print(\"Computing OT plan using EnergyFlow (ef.emd.emd)...\")\n",
    "# ef.emd is a module, the function is ef.emd.emd\n",
    "# It returns (dist, flow) when return_flow=True\n",
    "# The flow is returned as a dense matrix of shape (N, M)\n",
    "dist_val, gamma = ef.emd.emd(ev_source, ev_target, return_flow=True)\n",
    "\n",
    "print(f\"EMD Distance: {dist_val}\")\n",
    "print(f\"Flow matrix shape: {gamma.shape}\")\n",
    "print(f\"Max flow weight in gamma: {gamma.max()}\")\n",
    "\n",
    "# Plot Static Transport Plan\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Source\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X_source[:, 0], X_source[:, 1], s=w_source*1000, c='r', alpha=0.6, label=source_name)\n",
    "plt.title(f\"Source ({source_name})\")\n",
    "plt.xlim(-0.8, 0.8); plt.ylim(-0.8, 0.8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Target\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X_target[:, 0], X_target[:, 1], s=w_target*1000, c='b', alpha=0.6, label=target_name)\n",
    "plt.title(f\"Target ({target_name})\")\n",
    "plt.xlim(-0.8, 0.8); plt.ylim(-0.8, 0.8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Transport Lines\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(f\"Transport Plan (EMD={dist_val:.4f})\")\n",
    "# Draw lines for significant transport\n",
    "# Lower threshold to ensure visibility\n",
    "threshold = gamma.max() * 0.01 \n",
    "count_lines = 0\n",
    "for i in range(len(X_source)):\n",
    "    for j in range(len(X_target)):\n",
    "        if gamma[i, j] > threshold:\n",
    "            plt.plot([X_source[i, 0], X_target[j, 0]], [X_source[i, 1], X_target[j, 1]], \n",
    "                     'k-', alpha=0.2, lw=gamma[i, j]*200)\n",
    "            count_lines += 1\n",
    "            \n",
    "print(f\"Drawn {count_lines} transport lines (threshold={threshold:.6f}).\")\n",
    "\n",
    "plt.scatter(X_source[:, 0], X_source[:, 1], s=w_source*200, c='r', alpha=0.4)\n",
    "plt.scatter(X_target[:, 0], X_target[:, 1], s=w_target*200, c='b', alpha=0.4)\n",
    "plt.xlim(-0.8, 0.8); plt.ylim(-0.8, 0.8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ANIMATION\n",
    "# ---------------------------------------------------------\n",
    "# We interpolate between the two distributions: mu(t) = argmin_mu (1-t)W(mu0, mu) + t*W(mu1, mu)\n",
    "# For discrete measures, this corresponds to moving particles along the transport lines.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.set_xlim(-0.8, 0.8)\n",
    "ax.set_ylim(-0.8, 0.8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_title(f\"Optimal Transport Interpolation ({source_name} -> {target_name})\")\n",
    "\n",
    "# Prepare particle paths\n",
    "# Each entry in gamma[i, j] represents a \"packet\" of energy moving from X_source[i] to X_target[j]\n",
    "paths = []\n",
    "weights = []\n",
    "colors = []\n",
    "\n",
    "# Use a very low threshold for animation to include most particles\n",
    "anim_threshold = 1e-8\n",
    "\n",
    "for i in range(len(X_source)):\n",
    "    for j in range(len(X_target)):\n",
    "        if gamma[i, j] > anim_threshold:\n",
    "            start = X_source[i]\n",
    "            end = X_target[j]\n",
    "            paths.append((start, end))\n",
    "            weights.append(gamma[i, j])\n",
    "\n",
    "weights = np.array(weights)\n",
    "# Normalize weights for display size\n",
    "s_scale = 2000\n",
    "\n",
    "scatter = ax.scatter([], [], s=[], c=[], alpha=0.6)\n",
    "\n",
    "def update(frame):\n",
    "    t = frame / 20.0 # 0 to 1\n",
    "    \n",
    "    # If t > 1, reverse (ping-pong)\n",
    "    if t > 1.0: t = 2.0 - t\n",
    "    \n",
    "    current_positions = []\n",
    "    current_colors = []\n",
    "    \n",
    "    for k, (start, end) in enumerate(paths):\n",
    "        pos = (1 - t) * start + t * end\n",
    "        current_positions.append(pos)\n",
    "        # Color interpolation: Red (Source) -> Blue (Target)\n",
    "        current_colors.append((1-t, 0, t))\n",
    "        \n",
    "    current_positions = np.array(current_positions)\n",
    "    \n",
    "    # FIX: Handle empty arrays to prevent IndexError\n",
    "    if current_positions.shape[0] == 0:\n",
    "        current_positions = np.zeros((0, 2))\n",
    "    \n",
    "    scatter.set_offsets(current_positions)\n",
    "    scatter.set_sizes(weights * s_scale)\n",
    "    scatter.set_color(current_colors)\n",
    "    return scatter,\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, frames=40, interval=100, blit=True)\n",
    "plt.close()\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OT COMPUTATION (EnergyFlow / CPU)\n",
    "# ---------------------------------------------------------\n",
    "# Uses EnergyFlow (ef.emd.emd) for all calculations to ensure IRC safety.\n",
    "# This runs on CPU using the FastEMD C++ backend provided by EnergyFlow.\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def compute_ot_pair_ef(i, j, Xi, wi, Xj, wj):\n",
    "    \"\"\"\n",
    "    Compute EMD between jet i and jet j using EnergyFlow.\n",
    "    \"\"\"\n",
    "    # Construct events: (pt, y, phi)\n",
    "    # Xi is (y, phi), wi is pt\n",
    "    ev_i = np.column_stack((wi, Xi))\n",
    "    ev_j = np.column_stack((wj, Xj))\n",
    "    \n",
    "    # Compute EMD\n",
    "    # R=1.0 is standard, but EMD is linear in R anyway for fixed R.\n",
    "    # We use the default settings which correspond to standard EMD.\n",
    "    # Note: ef.emd is a module, the function is ef.emd.emd\n",
    "    val = ef.emd.emd(ev_i, ev_j)\n",
    "    return i, j, float(val)\n",
    "\n",
    "print(\"Computing pairwise EMD using EnergyFlow (CPU parallel)...\")\n",
    "N = len(jets_X)\n",
    "n_cores = min(8, multiprocessing.cpu_count())\n",
    "\n",
    "# Generate pairs (upper triangle)\n",
    "pairs = [(i, j) for i in range(N) for j in range(i+1, N)]\n",
    "print(f\"Total jets: {N}\")\n",
    "print(f\"Total pairs to compute: {len(pairs)}\")\n",
    "print(f\"Using {n_cores} cores.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run parallel computation\n",
    "# We pass the data explicitly to avoid overhead if possible, \n",
    "# though joblib handles shared memory well for read-only data.\n",
    "results = Parallel(n_jobs=n_cores, verbose=5)(\n",
    "    delayed(compute_ot_pair_ef)(i, j, jets_X[i], jets_w[i], jets_X[j], jets_w[j]) for i, j in pairs\n",
    ")\n",
    "\n",
    "# Fill matrix\n",
    "D = np.zeros((N, N))\n",
    "for i, j, val in results:\n",
    "    D[i, j] = val\n",
    "    D[j, i] = val\n",
    "np.fill_diagonal(D, 0.0)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Computation complete in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Average time per pair: {(end_time - start_time)/len(pairs)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08516281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ANALYSIS & PLOTS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Q/G Only t-SNE\n",
    "# ---------------------------------------------------------\n",
    "# Filter for Quark (1) and Gluon (0) only\n",
    "qg_indices = np.where((labels == 0) | (labels == 1))[0]\n",
    "\n",
    "if len(qg_indices) > 0:\n",
    "    print(f\"Running t-SNE for Q/G jets only ({len(qg_indices)} jets)...\")\n",
    "    \n",
    "    # Extract submatrix\n",
    "    D_qg = D[np.ix_(qg_indices, qg_indices)]\n",
    "    labels_qg = labels[qg_indices]\n",
    "    \n",
    "    # Run t-SNE\n",
    "    tsne_qg = TSNE(n_components=2, metric='precomputed', init='random', random_state=42, perplexity=30)\n",
    "    emb_qg = tsne_qg.fit_transform(D_qg)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in [0, 1]: # Gluon, Quark\n",
    "        if i in labels_qg:\n",
    "            mask = labels_qg == i\n",
    "            plt.scatter(emb_qg[mask, 0], emb_qg[mask, 1], label=class_names[i], s=40, alpha=0.8)\n",
    "            \n",
    "    plt.title('t-SNE embedding: Quark vs Gluon Jets')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Q/G jets found for separate plot.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Full t-SNE (All Classes)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Running t-SNE for all classes...\")\n",
    "tsne = TSNE(n_components=2, metric='precomputed', init='random', random_state=42, perplexity=30)\n",
    "emb = tsne.fit_transform(D)\n",
    "\n",
    "# Plot 1: Standard t-SNE with consistent legend\n",
    "plt.figure(figsize=(10, 8))\n",
    "present_classes = np.unique(labels)\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in present_classes:\n",
    "    mask = labels == i\n",
    "    plt.scatter(emb[mask, 0], emb[mask, 1], label=class_names[i], s=40, alpha=0.8)\n",
    "\n",
    "plt.title('t-SNE embedding of All Jets (Quark, Gluon, Top)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977dfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Morphological Confusion Matrix\n",
    "# For each class i, show the i-sample closest to class j on average\n",
    "n_classes = len(present_classes)\n",
    "out_dir = 'figures/confusion_matrix'\n",
    "import os\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "if n_classes > 1:\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    # Modest mass cut to accentuate morphological differences (25th percentile)\n",
    "    if 'jets_pt' in globals() or 'jets_pt' in locals():\n",
    "        mass_thresh = np.percentile(jets_pt, 25)\n",
    "    else:\n",
    "        mass_thresh = 0.0\n",
    "    print(f\"Using mass threshold (25th percentile): {mass_thresh:.3f}\")\n",
    "\n",
    "    saved_files = []\n",
    "\n",
    "    for i_idx, i in enumerate(present_classes):\n",
    "        inds_i_all = np.where(labels == i)[0]\n",
    "        # Apply mass filter but fall back to all indices if none pass\n",
    "        if 'jets_pt' in globals() or 'jets_pt' in locals():\n",
    "            inds_i = inds_i_all[jets_pt[inds_i_all] >= mass_thresh]\n",
    "            if len(inds_i) == 0:\n",
    "                inds_i = inds_i_all\n",
    "        else:\n",
    "            inds_i = inds_i_all\n",
    "\n",
    "        for j_idx, j in enumerate(present_classes):\n",
    "            inds_j_all = np.where(labels == j)[0]\n",
    "            if 'jets_pt' in globals() or 'jets_pt' in locals():\n",
    "                inds_j = inds_j_all[jets_pt[inds_j_all] >= mass_thresh]\n",
    "                if len(inds_j) == 0:\n",
    "                    inds_j = inds_j_all\n",
    "            else:\n",
    "                inds_j = inds_j_all\n",
    "\n",
    "            # Submatrix of distances between class i and class j\n",
    "            dsub = D[np.ix_(inds_i, inds_j)]\n",
    "\n",
    "            # Find the jets in class i with smallest average distance to class j\n",
    "            avg_dist = dsub.mean(axis=1)\n",
    "            sorted_local = np.argsort(avg_dist)\n",
    "            # Map to global indices and take up to 3 prototypes\n",
    "            proto_globals = [inds_i[idx] for idx in sorted_local[:3]]\n",
    "\n",
    "            # Plot main subplot using the most prototypical (rank 1)\n",
    "            best_global_idx = proto_globals[0]\n",
    "            ax = plt.subplot(n_classes, n_classes, i_idx * n_classes + j_idx + 1)\n",
    "            # Increase scale so jets fill the subplot and use larger markers for visibility\n",
    "            plot_jet_scatter(ax, 0, 0, jets_X[best_global_idx], jets_w[best_global_idx], scale=1.2, max_markersize=150)\n",
    "            ax.set_xlim(-0.9, 0.9); ax.set_ylim(-0.9, 0.9)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "            if i_idx == 0:\n",
    "                plt.title(f\"Closest to\\n{class_names[j]}\", fontsize=12)\n",
    "            if j_idx == 0:\n",
    "                plt.ylabel(f\"From\\n{class_names[i]}\", fontsize=12, rotation=0, labelpad=40)\n",
    "\n",
    "            # Save top-3 prototype images for this cell\n",
    "            for rank, gidx in enumerate(proto_globals):\n",
    "                fig_single = plt.figure(figsize=(3, 3))\n",
    "                ax_s = fig_single.add_subplot(1, 1, 1)\n",
    "                plot_jet_scatter(ax_s, 0, 0, jets_X[gidx], jets_w[gidx], scale=1.2, max_markersize=150)\n",
    "                ax_s.set_xlim(-0.9, 0.9); ax_s.set_ylim(-0.9, 0.9)\n",
    "                ax_s.axis('off')\n",
    "                safe_i = str(class_names[i]).replace(' ', '_')\n",
    "                safe_j = str(class_names[j]).replace(' ', '_')\n",
    "                fname = os.path.join(out_dir, f\"{safe_i}_to_{safe_j}_proto_rank{rank+1}.png\")\n",
    "                fig_single.savefig(fname, dpi=150, bbox_inches='tight', pad_inches=0.08)\n",
    "                plt.close(fig_single)\n",
    "                saved_files.append(fname)\n",
    "\n",
    "    # Save the assembled grid figure as well\n",
    "    grid_fname = os.path.join(out_dir, 'morph_confusion_matrix_grid.png')\n",
    "    fig.savefig(grid_fname, dpi=200, bbox_inches='tight')\n",
    "    saved_files.append(grid_fname)\n",
    "\n",
    "    plt.suptitle('Morphological Confusion Matrix\\\\n(Representative jets)', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Saved {len(saved_files)} files to {out_dir}:\\n - \" + \"\\n - \".join(saved_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Jet Mass Distribution with Medoids\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Calculate absolute jet masses from constituents\n",
    "# We compute this directly from the particle 4-vectors to ensure accuracy\n",
    "print(\"Calculating jet masses from constituents...\")\n",
    "m_list = []\n",
    "for i in range(len(jets_X)):\n",
    "    # Reconstruct constituent 4-vectors\n",
    "    # jets_w is normalized pT fraction, jets_pt is total pT\n",
    "    pt_i = jets_w[i] * jets_pt[i]\n",
    "    y_i = jets_X[i][:, 0]\n",
    "    phi_i = jets_X[i][:, 1]\n",
    "    \n",
    "    # Standard invariant mass calculation\n",
    "    # m^2 = E^2 - P^2\n",
    "    # Assumes massless constituents (p ~ E)\n",
    "    # E = pt * cosh(y)\n",
    "    # Px = pt * cos(phi)\n",
    "    # Py = pt * sin(phi)\n",
    "    # Pz = pt * sinh(y)\n",
    "    \n",
    "    E = np.sum(pt_i * np.cosh(y_i))\n",
    "    Px = np.sum(pt_i * np.cos(phi_i))\n",
    "    Py = np.sum(pt_i * np.sin(phi_i))\n",
    "    Pz = np.sum(pt_i * np.sinh(y_i))\n",
    "    \n",
    "    m2 = E**2 - Px**2 - Py**2 - Pz**2\n",
    "    m_list.append(np.sqrt(max(0, m2)))\n",
    "\n",
    "abs_masses = np.array(m_list)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "plot_classes = [c for c in [2, 1, 0] if c in present_classes]\n",
    "n_rows = len(plot_classes) + 1\n",
    "height_ratios = [1]*len(plot_classes) + [3]\n",
    "\n",
    "gs = fig.add_gridspec(n_rows, 1, height_ratios=height_ratios, hspace=0.1)\n",
    "\n",
    "# Histogram (Bottom)\n",
    "ax_hist = fig.add_subplot(gs[-1])\n",
    "# Range: 0 to 250 GeV (typical for these datasets)\n",
    "counts, bins, _ = ax_hist.hist([abs_masses[labels==i] for i in present_classes], \n",
    "                               bins=20, range=(0, 250), \n",
    "                               stacked=True, density=True, alpha=0.5, \n",
    "                               label=[class_names[i] for i in present_classes])\n",
    "ax_hist.legend(fontsize='x-large')\n",
    "ax_hist.set_xlabel(\"Jet Mass [GeV]\", fontsize='x-large')\n",
    "ax_hist.set_ylabel(\"Density\", fontsize='x-large')\n",
    "ax_hist.set_xlim(0, 250)\n",
    "\n",
    "# Medoid Rows\n",
    "for row_idx, cls_id in enumerate(plot_classes):\n",
    "    ax_row = fig.add_subplot(gs[row_idx], sharex=ax_hist)\n",
    "    ax_row.axis('off')\n",
    "    ax_row.set_xlim(0, 250)\n",
    "    ax_row.set_ylim(-1, 1)\n",
    "    \n",
    "    ax_row.text(-0.02, 0.5, f\"{class_names[cls_id]}\\nMedoids\", \n",
    "                transform=ax_row.transAxes, ha='right', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "    for k in range(len(bins)-1):\n",
    "        mask = (abs_masses >= bins[k]) & (abs_masses < bins[k+1]) & (labels == cls_id)\n",
    "        idxs = np.where(mask)[0]\n",
    "        \n",
    "        if len(idxs) > 2:\n",
    "            d_sub = D[np.ix_(idxs, idxs)]\n",
    "            medoid_local = np.argmin(d_sub.sum(axis=1))\n",
    "            medoid_idx = idxs[medoid_local]\n",
    "            \n",
    "            x_c = (bins[k] + bins[k+1]) / 2\n",
    "            x_norm = (x_c - 0) / 250.0\n",
    "            \n",
    "            ax_ins = inset_axes(ax_row, width=\"80%\", height=\"90%\", \n",
    "                               bbox_to_anchor=(x_norm - 0.5/20, 0, 1/20, 1), \n",
    "                               bbox_transform=ax_row.transAxes, loc='center')\n",
    "            \n",
    "            plot_jet_scatter(ax_ins, 0, 0, jets_X[medoid_idx], jets_w[medoid_idx], scale=0.8, max_markersize=40)\n",
    "            ax_ins.set_xticks([])\n",
    "            ax_ins.set_yticks([])\n",
    "            ax_ins.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Jet Multiplicity Distribution with Medoids\n",
    "# ---------------------------------------------------------\n",
    "print(\"Generating jet multiplicity distribution + medoids...\")\n",
    "\n",
    "# Rebinning factor (group integer multiplicities into bins of width mult_rebin)\n",
    "# Set to 1 for no rebinning, 2 for pairs (0-1,2-3,...), etc.\n",
    "mult_rebin = 5  # <-- change this value to rebin multiplicities\n",
    "\n",
    "# Compute multiplicity (number of constituents) per jet\n",
    "multiplicities = np.array([len(w) for w in jets_w])\n",
    "# Grouped multiplicities\n",
    "grouped = multiplicities // mult_rebin\n",
    "group_max = int(grouped.max()) if grouped.size > 0 else 0\n",
    "\n",
    "fig_mult = plt.figure(figsize=(14, 12))\n",
    "plot_classes = [c for c in [2, 1, 0] if c in present_classes]\n",
    "n_rows = len(plot_classes) + 1\n",
    "height_ratios = [1]*len(plot_classes) + [3]\n",
    "\n",
    "gs2 = fig_mult.add_gridspec(n_rows, 1, height_ratios=height_ratios, hspace=0.1)\n",
    "\n",
    "# Histogram (Bottom) for grouped multiplicity\n",
    "ax_hist_m = fig_mult.add_subplot(gs2[-1])\n",
    "# Build grouped arrays per class\n",
    "grouped_per_class = [grouped[labels==i] for i in present_classes]\n",
    "# Bins for grouped values\n",
    "bins_mult = np.arange(0, group_max + 2) - 0.5\n",
    "counts_m, _, _ = ax_hist_m.hist(grouped_per_class, \n",
    "                                 bins=bins_mult, stacked=True, density=True, alpha=0.6, \n",
    "                                 label=[class_names[i] for i in present_classes])\n",
    "# xticks: label ranges\n",
    "xticks = np.arange(0, group_max+1)\n",
    "xtick_labels = [f\"{g*mult_rebin}-{g*mult_rebin + mult_rebin - 1}\" if mult_rebin>1 else f\"{g*mult_rebin}\" for g in xticks]\n",
    "ax_hist_m.set_xticks(xticks)\n",
    "ax_hist_m.set_xticklabels(xtick_labels, rotation=45)\n",
    "ax_hist_m.set_xlabel(\"Jet constituent multiplicity\", fontsize='x-large')\n",
    "ax_hist_m.set_ylabel(\"Density\", fontsize='x-large')\n",
    "ax_hist_m.set_xlim(-0.5, group_max + 0.5)\n",
    "ax_hist_m.legend(fontsize='x-large')\n",
    "\n",
    "# Medoid rows for multiplicity (same layout as mass medoids)\n",
    "for row_idx, cls_id in enumerate(plot_classes):\n",
    "    ax_row = fig_mult.add_subplot(gs2[row_idx], sharex=ax_hist_m)\n",
    "    ax_row.axis('off')\n",
    "    ax_row.set_xlim(-0.5, group_max + 0.5)\n",
    "    ax_row.set_ylim(-1, 1)\n",
    "    \n",
    "    ax_row.text(-0.02, 0.5, f\"{class_names[cls_id]}\\nMult. Medoids\", \n",
    "                transform=ax_row.transAxes, ha='right', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Iterate over grouped multiplicity bins\n",
    "    for g in range(0, group_max+1):\n",
    "        mask = (grouped == g) & (labels == cls_id)\n",
    "        idxs = np.where(mask)[0]\n",
    "        if len(idxs) > 2:\n",
    "            d_sub = D[np.ix_(idxs, idxs)]\n",
    "            medoid_local = np.argmin(d_sub.sum(axis=1))\n",
    "            medoid_idx = idxs[medoid_local]\n",
    "\n",
    "            # place inset roughly at the appropriate multiplicity location\n",
    "            if group_max > 0:\n",
    "                x_norm = g / group_max\n",
    "            else:\n",
    "                x_norm = 0.5\n",
    "\n",
    "            width_frac = 1.0 / (group_max + 1 if group_max > 0 else 1)\n",
    "            ax_ins = inset_axes(ax_row, width=\"80%\", height=\"90%\", \n",
    "                                bbox_to_anchor=(x_norm - 0.5*width_frac, 0, width_frac, 1), \n",
    "                                bbox_transform=ax_row.transAxes, loc='center')\n",
    "            plot_jet_scatter(ax_ins, 0, 0, jets_X[medoid_idx], jets_w[medoid_idx], scale=0.8, max_markersize=40)\n",
    "            ax_ins.set_xticks([])\n",
    "            ax_ins.set_yticks([])\n",
    "            ax_ins.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddd302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# DETAILED MEDOID VISUALIZATION (Specific Mass Bin)\n",
    "# ---------------------------------------------------------\n",
    "# Plot a larger version of the Quark, Gluon, and Top medoids \n",
    "# for a specific mass bin (e.g., near the W/Top mass peak or a generic QCD mass).\n",
    "\n",
    "# Ensure we have absolute jet masses (in GeV)\n",
    "if 'abs_masses' not in locals():\n",
    "    if 'masses' in locals() and 'jets_pt' in locals():\n",
    "        print(\"Calculating absolute masses from normalized masses...\")\n",
    "        abs_masses = masses * jets_pt\n",
    "    else:\n",
    "        print(\"Calculating jet masses from constituents...\")\n",
    "        # Compute mass from jets_X, jets_w, jets_pt\n",
    "        m_list = []\n",
    "        for i in range(len(jets_X)):\n",
    "            pt_i = jets_w[i] * jets_pt[i]\n",
    "            y_i = jets_X[i][:, 0]\n",
    "            phi_i = jets_X[i][:, 1]\n",
    "            \n",
    "            E = np.sum(pt_i * np.cosh(y_i))\n",
    "            Px = np.sum(pt_i * np.cos(phi_i))\n",
    "            Py = np.sum(pt_i * np.sin(phi_i))\n",
    "            Pz = np.sum(pt_i * np.sinh(y_i))\n",
    "            \n",
    "            m2 = E**2 - Px**2 - Py**2 - Pz**2\n",
    "            m_list.append(np.sqrt(max(0, m2)))\n",
    "        abs_masses = np.array(m_list)\n",
    "\n",
    "# Target Mass Range in GeV\n",
    "# Top Quark mass is approx 173 GeV. W Boson is approx 80 GeV.\n",
    "target_mass_min = 170.0 \n",
    "target_mass_max = 175.0\n",
    "\n",
    "print(f\"Finding representative jets (medoids) in mass range [{target_mass_min:.1f}, {target_mass_max:.1f}] GeV...\")\n",
    "\n",
    "# Find indices in this bin using absolute mass\n",
    "mask_bin = (abs_masses >= target_mass_min) & (abs_masses < target_mass_max)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plot_classes = [c for c in [1, 0, 2] if c in present_classes] # Quark, Gluon, Top\n",
    "\n",
    "for i, cls_id in enumerate(plot_classes):\n",
    "    # Filter by class\n",
    "    mask = mask_bin & (labels == cls_id)\n",
    "    idxs = np.where(mask)[0]\n",
    "    \n",
    "    if len(idxs) > 0:\n",
    "        # Compute medoid\n",
    "        d_sub = D[np.ix_(idxs, idxs)]\n",
    "        medoid_local = np.argmin(d_sub.sum(axis=1))\n",
    "        medoid_idx = idxs[medoid_local]\n",
    "        \n",
    "        # Plot\n",
    "        ax = plt.subplot(1, 3, i + 1)\n",
    "        plot_jet_scatter(ax, 0, 0, jets_X[medoid_idx], jets_w[medoid_idx], scale=0.8, max_markersize=200)\n",
    "        \n",
    "        ax.set_xlim(-1.0, 1.0)\n",
    "        ax.set_ylim(-1.0, 1.0)\n",
    "        ax.set_title(f\"{class_names[cls_id]} Medoid\\nMass $\\\\in$ [{target_mass_min}, {target_mass_max}] GeV\", fontsize=14)\n",
    "        ax.set_xlabel(\"$\\\\eta$\")\n",
    "        if i == 0: ax.set_ylabel(\"$\\\\phi$\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        print(f\"No {class_names[cls_id]} jets found in this mass bin.\")\n",
    "        # Create empty placeholder\n",
    "        ax = plt.subplot(1, 3, i + 1)\n",
    "        ax.text(0.5, 0.5, \"No Jets Found\", ha='center', va='center')\n",
    "        ax.set_title(f\"{class_names[cls_id]} Medoid\")\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CLASSIFICATION: Top vs. QCD (Quark/Gluon) using EMD\n",
    "# ---------------------------------------------------------\n",
    "# We use the pairwise EMD matrix to perform k-Nearest Neighbor (k-NN) classification.\n",
    "# This demonstrates the power of the metric space structure for distinguishing jet classes.\n",
    "# Reference: Komiske, Metodiev, Thaler, \"The Metric Space of Collider Events\", PRL 123 (2019)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "print(\"Running Top vs. QCD Classification using EMD-based k-NN...\")\n",
    "\n",
    "# 1. Prepare Data\n",
    "# Signal: Top (Label 2)\n",
    "# Background: QCD (Quark=1, Gluon=0)\n",
    "is_top = (labels == 2)\n",
    "is_qcd = (labels == 0) | (labels == 1)\n",
    "\n",
    "# Filter dataset to only include these (should be all, but good to be safe)\n",
    "valid_mask = is_top | is_qcd\n",
    "valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "# Create binary labels for classification: 1 for Top, 0 for QCD\n",
    "y_binary = (labels[valid_indices] == 2).astype(int)\n",
    "indices = np.arange(len(valid_indices))\n",
    "\n",
    "# 2. Split into Train and Test\n",
    "# We split the *indices* of our valid data so we can slice the distance matrix D\n",
    "idx_train, idx_test, y_train, y_test = train_test_split(\n",
    "    indices, y_binary, test_size=0.3, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "# Map back to global indices in D\n",
    "global_idx_train = valid_indices[idx_train]\n",
    "global_idx_test = valid_indices[idx_test]\n",
    "\n",
    "print(f\"Training set: {len(idx_train)} jets\")\n",
    "print(f\"Test set:     {len(idx_test)} jets\")\n",
    "\n",
    "# 3. Prepare Distance Matrices for k-NN\n",
    "# k-NN with 'precomputed' metric requires:\n",
    "# Fit: (n_train, n_train) distance matrix\n",
    "# Predict: (n_test, n_train) distance matrix\n",
    "\n",
    "# Extract submatrix for training (train vs train)\n",
    "D_train = D[np.ix_(global_idx_train, global_idx_train)]\n",
    "\n",
    "# Extract submatrix for testing (test vs train)\n",
    "D_test = D[np.ix_(global_idx_test, global_idx_train)]\n",
    "\n",
    "# 4. Train k-NN Classifier\n",
    "# k is a hyperparameter. A typical heuristic is sqrt(N_train), but we can pick a fixed value.\n",
    "k = 16\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric='precomputed')\n",
    "knn.fit(D_train, y_train)\n",
    "\n",
    "# 5. Predict on Test Set\n",
    "# Get probability of being Top (class 1)\n",
    "# The probability is the fraction of the k nearest neighbors that are Top jets\n",
    "y_score = knn.predict_proba(D_test)[:, 1]\n",
    "\n",
    "# 6. Compute ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 7. Plot Results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'EMD k-NN (k={k}) (AUC = {roc_auc:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate (QCD tagged as Top)')\n",
    "ax1.set_ylabel('True Positive Rate (Top efficiency)')\n",
    "ax1.set_title('ROC Curve: Top vs. QCD Classification')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Discriminant Distribution\n",
    "ax2.hist(y_score[y_test==0], bins=20, range=(0, 1), density=True, alpha=0.5, color='blue', label='QCD (True)')\n",
    "ax2.hist(y_score[y_test==1], bins=20, range=(0, 1), density=True, alpha=0.5, color='red', label='Top (True)')\n",
    "ax2.set_xlabel(f'k-NN Discriminant (P(Top) with k={k})')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Classifier Score Distribution')\n",
    "ax2.legend(loc='upper center')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Classification AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78def18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CLASSIFICATION: Top vs. QCD using Energy Flow Network (EFN)\n",
    "# ---------------------------------------------------------\n",
    "# We train a deep neural network (EFN) on the particle sets.\n",
    "# EFNs are IRC-safe architectures designed for point clouds.\n",
    "# Reference: Komiske, Metodiev, Thaler, \"Energy Flow Networks: Deep Sets for Particle Physics\", JHEP 01 (2019) 121\n",
    "# https://arxiv.org/abs/1810.05165\n",
    "\n",
    "# Install TensorFlow and tf_keras (required for compatibility with EnergyFlow on newer TF versions)\n",
    "# We use --no-deps to avoid messing up other dependencies if possible, but here we need to ensure they are installed.\n",
    "!pip install -q tensorflow tf_keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import importlib\n",
    "import energyflow\n",
    "\n",
    "# Set environment variable to ensure EnergyFlow uses the correct Keras backend if needed\n",
    "os.environ['TF_KERAS'] = '1' \n",
    "\n",
    "import energyflow.archs\n",
    "importlib.reload(energyflow.archs)\n",
    "\n",
    "# Now import EnergyFlow architectures\n",
    "try:\n",
    "    from energyflow.archs import EFN\n",
    "except ImportError:\n",
    "    # If it still fails, it might be a deeper issue with the backend. \n",
    "    # We try to reload the specific submodule if possible or warn the user.\n",
    "    print(\"Could not import EFN after reload. Trying to reload energyflow.archs.efn directly...\")\n",
    "    try:\n",
    "        import energyflow.archs.efn\n",
    "        importlib.reload(energyflow.archs.efn)\n",
    "        from energyflow.archs import EFN\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to import EFN: {e}\")\n",
    "        print(\"Please RESTART THE RUNTIME (Runtime > Restart session) and run this cell again.\")\n",
    "        raise\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Running Top vs. QCD Classification using EFN...\")\n",
    "\n",
    "# 1. Prepare Data\n",
    "# We need to convert our list of jets into a padded numpy array (N, M, 3)\n",
    "# Features: (z, y, phi) where z is pT fraction\n",
    "\n",
    "# Filter for Top (2) and QCD (0, 1)\n",
    "is_top = (labels == 2)\n",
    "is_qcd = (labels == 0) | (labels == 1)\n",
    "valid_mask = is_top | is_qcd\n",
    "valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "# Find max particles in the dataset\n",
    "max_len = max(len(jets_w[i]) for i in valid_indices)\n",
    "print(f\"Max particles per jet: {max_len}\")\n",
    "\n",
    "# Initialize arrays\n",
    "# We separate weights (z) and features (y, phi) because EFN expects them as separate inputs\n",
    "X_z = np.zeros((len(valid_indices), max_len))\n",
    "X_p = np.zeros((len(valid_indices), max_len, 2)) # (y, phi)\n",
    "Y_efn = np.zeros(len(valid_indices))\n",
    "\n",
    "for i, idx in enumerate(valid_indices):\n",
    "    # Get jet data\n",
    "    x_jet = jets_X[idx] # (M, 2) -> (y, phi)\n",
    "    w_jet = jets_w[idx] # (M,) -> z (normalized pt)\n",
    "    \n",
    "    n_particles = len(w_jet)\n",
    "    \n",
    "    # Fill arrays\n",
    "    X_z[i, :n_particles] = w_jet\n",
    "    X_p[i, :n_particles, 0] = x_jet[:, 0] # y\n",
    "    X_p[i, :n_particles, 1] = x_jet[:, 1] # phi\n",
    "    \n",
    "    # Label: 1 for Top, 0 for QCD\n",
    "    if labels[idx] == 2:\n",
    "        Y_efn[i] = 1\n",
    "    else:\n",
    "        Y_efn[i] = 0\n",
    "\n",
    "print(f\"Data shapes: Z={X_z.shape}, P={X_p.shape}\")\n",
    "print(f\"Labels shape: {Y_efn.shape}\")\n",
    "\n",
    "# 2. Split into Train/Val/Test\n",
    "# We split all arrays simultaneously\n",
    "X_z_train, X_z_test, X_p_train, X_p_test, Y_train, Y_test = train_test_split(\n",
    "    X_z, X_p, Y_efn, test_size=0.2, random_state=42, stratify=Y_efn\n",
    ")\n",
    "\n",
    "X_z_train, X_z_val, X_p_train, X_p_val, Y_train, Y_val = train_test_split(\n",
    "    X_z_train, X_p_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(Y_train)}, Val: {len(Y_val)}, Test: {len(Y_test)}\")\n",
    "\n",
    "# 3. Define EFN Architecture\n",
    "# input_dim=2 for (y, phi) - The weight z is handled separately by the architecture\n",
    "# Phi_sizes: Dense layers for per-particle mapping (Latent space dim is last layer)\n",
    "# F_sizes: Dense layers for global mapping (Classifier)\n",
    "efn = EFN(input_dim=2, \n",
    "          Phi_sizes=[100, 100, 128], \n",
    "          F_sizes=[100, 100, 100], \n",
    "          output_dim=1, \n",
    "          output_act='sigmoid',\n",
    "          loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "# 4. Train\n",
    "print(\"Training EFN...\")\n",
    "# EFN expects a list of inputs: [X_z, X_p]\n",
    "history = efn.fit([X_z_train, X_p_train], Y_train, \n",
    "                  epochs=20, \n",
    "                  batch_size=500, \n",
    "                  validation_data=([X_z_val, X_p_val], Y_val), \n",
    "                  verbose=1)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Evaluating on Test Set...\")\n",
    "preds = efn.predict([X_z_test, X_p_test])\n",
    "fpr_efn, tpr_efn, thresholds_efn = roc_curve(Y_test, preds)\n",
    "roc_auc_efn = auc(fpr_efn, tpr_efn)\n",
    "\n",
    "# 6. Plot Results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC Curve Comparison\n",
    "ax1.plot(fpr_efn, tpr_efn, color='green', lw=2, label=f'EFN (AUC = {roc_auc_efn:.3f})')\n",
    "# Add previous k-NN result if available\n",
    "if 'fpr' in locals() and 'tpr' in locals():\n",
    "    ax1.plot(fpr, tpr, color='darkorange', lw=2, linestyle='--', label=f'EMD k-NN (AUC = {roc_auc:.3f})')\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle=':')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve Comparison')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Training History\n",
    "ax2.plot(history.history['loss'], label='Train Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('EFN Training History')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"EFN Classification AUC: {roc_auc_efn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e11a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# t-SNE: Same embedding colored by jet mass\n",
    "# ---------------------------------------------------------\n",
    "# This cell plots the previously computed `emb` (t-SNE embedding)\n",
    "# and colors points by `abs_masses`. If `abs_masses` is missing,\n",
    "# it will be computed (may take a moment).\n",
    "\n",
    "if 'emb' not in globals() and 'emb' not in locals():\n",
    "    print(\"t-SNE embedding 'emb' not found. Run the Full t-SNE cell first.\")\n",
    "else:\n",
    "    if 'abs_masses' not in globals() and 'abs_masses' not in locals():\n",
    "        print(\"'abs_masses' not found  computing from constituents (this may take some time)...\")\n",
    "        m_list = []\n",
    "        for i in range(len(jets_X)):\n",
    "            pt_i = jets_w[i] * jets_pt[i]\n",
    "            y_i = jets_X[i][:, 0]\n",
    "            phi_i = jets_X[i][:, 1]\n",
    "            E = np.sum(pt_i * np.cosh(y_i))\n",
    "            Px = np.sum(pt_i * np.cos(phi_i))\n",
    "            Py = np.sum(pt_i * np.sin(phi_i))\n",
    "            Pz = np.sum(pt_i * np.sinh(y_i))\n",
    "            m2 = E**2 - Px**2 - Py**2 - Pz**2\n",
    "            m_list.append(np.sqrt(max(0, m2)))\n",
    "        abs_masses = np.array(m_list)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc = plt.scatter(emb[:, 0], emb[:, 1], c=abs_masses, cmap='plasma', s=40, alpha=0.85)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label('Jet mass [GeV]')\n",
    "    plt.title('t-SNE embedding colored by jet mass')\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ANIMATION (HD + configurable colormap)\n",
    "# ---------------------------------------------------------\n",
    "# Produces a higher-resolution transport-based prototype-cycle GIF and lets you\n",
    "# choose the colormap via `cmap_name`. This cell is a drop-in replacement\n",
    "# if you prefer HD output without modifying the earlier cells.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_dir = 'figures/confusion_matrix'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Configurable parameters\n",
    "N = 3\n",
    "frames_per_transition = 20\n",
    "class_order = [1, 0, 2]\n",
    "cmap_name = 'plasma'  # change to any matplotlib colormap\n",
    "gif_dpi = 200         # increase for higher resolution (e.g., 200 or 300)\n",
    "figsize = (6, 6)\n",
    "\n",
    "# Build prototypes\n",
    "prototypes = {}\n",
    "for cls in class_order:\n",
    "    if cls in present_classes:\n",
    "        inds = np.where(labels == cls)[0]\n",
    "        if len(inds) == 0:\n",
    "            continue\n",
    "        d_sub = D[np.ix_(inds, inds)]\n",
    "        avg_dist = d_sub.mean(axis=1)\n",
    "        sorted_local = np.argsort(avg_dist)\n",
    "        proto_globals = [int(inds[idx]) for idx in sorted_local[:N]]\n",
    "        prototypes[cls] = proto_globals\n",
    "\n",
    "# Sequence\n",
    "seq = []\n",
    "for r in range(N):\n",
    "    for cls in class_order:\n",
    "        if cls in prototypes and len(prototypes[cls]) > r:\n",
    "            seq.append((cls, prototypes[cls][r]))\n",
    "\n",
    "if len(seq) < 2:\n",
    "    print(\"Not enough prototypes to animate transport. Found:\", seq)\n",
    "else:\n",
    "    # Precompute flows\n",
    "    flows = []\n",
    "    for k in range(len(seq)):\n",
    "        g1 = seq[k][1]\n",
    "        g2 = seq[(k+1) % len(seq)][1]\n",
    "        X1 = np.asarray(jets_X[g1])\n",
    "        w1 = np.asarray(jets_w[g1])\n",
    "        X2 = np.asarray(jets_X[g2])\n",
    "        w2 = np.asarray(jets_w[g2])\n",
    "\n",
    "        ev1 = np.column_stack((w1, X1))\n",
    "        ev2 = np.column_stack((w2, X2))\n",
    "\n",
    "        try:\n",
    "            _, gamma = ef.emd.emd(ev1, ev2, return_flow=True)\n",
    "            gamma = np.asarray(gamma)\n",
    "            r = min(gamma.shape[0], X1.shape[0])\n",
    "            c = min(gamma.shape[1], X2.shape[0])\n",
    "            gamma = gamma[:r, :c]\n",
    "        except Exception as e:\n",
    "            print(f\"ef.emd.emd failed for pair {g1}->{g2}: {e}. Using None for gamma.\")\n",
    "            gamma = None\n",
    "\n",
    "        flows.append({'X1': X1, 'w1': w1, 'X2': X2, 'w2': w2, 'gamma': gamma, 'pair': (g1, g2)})\n",
    "\n",
    "    total_frames = len(flows) * frames_per_transition\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    s_scale = 2500\n",
    "\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "    def update(frame):\n",
    "        seg = frame // frames_per_transition\n",
    "        f_in_seg = frame % frames_per_transition\n",
    "        t = f_in_seg / float(max(1, frames_per_transition - 1))\n",
    "\n",
    "        data = flows[seg]\n",
    "        X1, X2, gamma, w1 = data['X1'], data['X2'], data['gamma'], data['w1']\n",
    "\n",
    "        ax.clear()\n",
    "        ax.axis('off')\n",
    "        ax.set_xlim(-0.9, 0.9)\n",
    "        ax.set_ylim(-0.9, 0.9)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        if gamma is None:\n",
    "            # fallback: linear interpolation, color by source weight\n",
    "            n = max(len(X1), len(X2))\n",
    "            X1p = np.vstack([X1, np.tile(X1[-1], (n - len(X1), 1))]) if len(X1) < n else X1[:n]\n",
    "            X2p = np.vstack([X2, np.tile(X2[-1], (n - len(X2), 1))]) if len(X2) < n else X2[:n]\n",
    "            pos = (1 - t) * X1p + t * X2p\n",
    "            wsrc = np.concatenate([w1, np.zeros(max(0, n - len(w1)))])\n",
    "            if wsrc.max() > 0:\n",
    "                colors = wsrc / (wsrc.max() + 1e-12)\n",
    "            else:\n",
    "                colors = np.ones_like(wsrc)\n",
    "            ax.scatter(pos[:, 0], pos[:, 1], s=30, c=colors, cmap=cmap, alpha=0.9, edgecolors='none')\n",
    "        else:\n",
    "            thresh = max(gamma.max() * 1e-8, 1e-12)\n",
    "            inds = np.argwhere(gamma > thresh)\n",
    "            if inds.size > 0:\n",
    "                xs = []\n",
    "                ys = []\n",
    "                ss = []\n",
    "                cs = []\n",
    "                gmax = gamma.max()\n",
    "                for (i, j) in inds:\n",
    "                    start = X1[i]\n",
    "                    end = X2[j]\n",
    "                    pos = (1 - t) * start + t * end\n",
    "                    q = gamma[i, j]\n",
    "                    xs.append(pos[0])\n",
    "                    ys.append(pos[1])\n",
    "                    ss.append(max(1.0, q * s_scale))\n",
    "                    cs.append(q / (gmax + 1e-12))\n",
    "                ax.scatter(xs, ys, s=ss, c=cs, cmap=cmap, alpha=0.95, edgecolors='none')\n",
    "\n",
    "        return []\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=total_frames, interval=80, blit=False)\n",
    "\n",
    "    gif_fname = os.path.join(out_dir, f'prototype_transport_cycle_top{N}_q_g_t_{cmap_name}_hd.gif')\n",
    "    print(f\"Saving HD transport-based prototype-cycle GIF to {gif_fname} (dpi={gif_dpi}) ...\")\n",
    "    anim.save(gif_fname, writer=PillowWriter(fps=12), dpi=gif_dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved HD transport-based prototype-cycle GIF: {gif_fname}\")\n",
    "    try:\n",
    "        display(HTML(f\"<img src=\\\"{gif_fname}\\\" style=\\\"max-width:480px;\\\">\"))\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55898208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# FRACTAL CORRELATION DIMENSION\n",
    "# ---------------------------------------------------------\n",
    "# We compute the correlation dimension of the dataset manifold\n",
    "# by analyzing the distribution of pairwise distances.\n",
    "\n",
    "print(\"Computing Fractal Correlation Dimensions...\")\n",
    "\n",
    "# Prepare bins for the histogram of distances (EMDs)\n",
    "# Range: 10^-2 to 10^0 (0.01 to 1.0)\n",
    "bins = 10**np.linspace(-2, 0, 60)\n",
    "reg = 10**-30 # Regularization to avoid log(0)\n",
    "midbins = (bins[:-1] + bins[1:])/2\n",
    "dmidbins = np.log(midbins[1:]) - np.log(midbins[:-1]) + reg\n",
    "midbins2 = (midbins[:-1] + midbins[1:])/2\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Iterate over each class to compute its dimension\n",
    "for i in present_classes:\n",
    "    # Get indices for this class\n",
    "    inds = np.where(labels == i)[0]\n",
    "    \n",
    "    # Extract sub-matrix of distances\n",
    "    # We only need the upper triangle (excluding diagonal)\n",
    "    # D is symmetric, so triu is sufficient.\n",
    "    d_sub = D[np.ix_(inds, inds)]\n",
    "    \n",
    "    # Get upper triangle values (k=1 removes diagonal 0s)\n",
    "    # Flatten to 1D array\n",
    "    emd_vals = d_sub[np.triu_indices_from(d_sub, k=1)]\n",
    "    \n",
    "    # Compute histogram of distances\n",
    "    # counts is the number of pairs with distance in each bin\n",
    "    # We use cumsum because correlation sum C(r) is the fraction of pairs with dist < r\n",
    "    hist_counts, _ = np.histogram(emd_vals, bins=bins)\n",
    "    cdf_counts = np.cumsum(hist_counts)\n",
    "    \n",
    "    # Compute local slope of log(C(r)) vs log(r)\n",
    "    # dim = d(log C(r)) / d(log r)\n",
    "    dims = (np.log(cdf_counts[1:] + reg) - np.log(cdf_counts[:-1] + reg)) / dmidbins\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(midbins2, dims, '-', label=f'{class_names[i]} Jets', alpha=0.8, linewidth=2)\n",
    "\n",
    "# Styling\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Energy Scale (EMD)')\n",
    "plt.ylabel('Correlation Dimension')\n",
    "plt.xlim(0.02, 1.0)\n",
    "plt.ylim(0, 10)\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.title('Fractal Correlation Dimension vs. Scale')\n",
    "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
